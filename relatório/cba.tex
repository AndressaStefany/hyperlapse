\documentclass[conference,harvard,brazil,english]{sbatex}
\usepackage{url}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage[compatibility=false]{caption}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{dred}{rgb}{0.545,0,0}
\definecolor{dblue}{rgb}{0,0,0.545}
\definecolor{lgrey}{rgb}{0.9,0.9,0.9}
\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\lstdefinelanguage{cpp}{
      %backgroundcolor=\color{lgrey},  
      basicstyle=\footnotesize \ttfamily \color{black} \bfseries,   
      breakatwhitespace=false,       
      breaklines=true,               
      captionpos=b,                   
      commentstyle=\color{dkgreen},   
      %deletekeywords={...},          
      escapeinside={\%*}{*)},                  
      %frame=single,                  
      language=C++,                
      keywordstyle=\color{purple},  
      morekeywords={BRIEFDescriptorConfig,string,TiXmlNode,DetectorDescriptorConfigContainer,istringstream,cerr,exit}, 
      identifierstyle=\color{black},
      stringstyle=\color{blue},      
      numbers=left,                 
      numbersep=1pt,                  
      numberstyle=\tiny\color{black}, 
      rulecolor=\color{black},        
      showspaces=false,               
      showstringspaces=false,        
      showtabs=false,                
      stepnumber=1,                   
      tabsize=5,                     
      title=\lstname,                 
    }
\usepackage{ae}
%
% LaTeX2e class SBATeX
%
% Versão 1.0 alpha
%   Walter Fetter Lages
%   w.fetter@ieee.org
%
% Este arquivo cba.tex é uma adaptação do arquivo revista.tex,
% Versão: 1.0 alpha, desenvolvido por Maurício C. de Oliveira,
% mcdeoliveira@ieee.org.
%
% As adaptações fazem com que, por default, sejam utilizadas
% as opções adequadas para o formato do CBA ou SBAI, ao contrário do arquivo
% revista.tex, que, por default, utiliza opções adequadas para o formato
% da Revista da SBA.
%
%
% --------------------------------------------------
%
% Para compilar este exemplo use a seqüência de comandos:
%
%     latex cba
%     bibtex cba
%     latex cba
%     latex cba
%
% Para gerar um arquivo Postscript (.ps):
%
%     dvips -t a4 cba
%
% Para gerar um arquivo Portable Document Format (.pdf):
%
%     dvips -Ppdf -t a4 cba
%     ps2pdf -dMaxSubsetPct=100 -dSubsetFonts=true -dEmbedAllFonts=true -dCompatibilityLevel=1.2 -sPAPERSIZE=a4 cba.ps
%

% --------------------------------------------------
%  Estes comandos são necessários apenas para a
%  a geração deste artigo exemplo. Eles não fazem
%  parte do estilo SBATeX.
% --------------------------------------------------
\makeatletter
\def\verbatim@font{\normalfont\ttfamily\footnotesize}
\makeatother
\usepackage{amsmath}
% --------------------------------------------------


\begin{document}

% CABEÇALHO

\title{Uso do Fluxo Óptico para criação do Hyperlapse}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% O processo de revisao do CBA 2014 sera DOUBLE BLIND, portanto NAO inclua
% autores na versão que será submetida para revisão
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author{Andressa Stéfany Silva de Oliveira}{astefanysoliveira@gmail.com}
\address{Graduanda em Engenharia de Computação\\ Universidade do Rio Grande do Norte\\ Natal, RN, Brasil}

\twocolumn[

\maketitle

\selectlanguage{brazil}
\begin{abstract}
  A partir do estudo de Processamento Digital de Imagens, houve utilização das técnicas de Fluxo Óptico para a estabilização de um vídeo e a aceleração deste, onde o objetivo é a criação do efeito hyperlapse em um vídeo, isto é, a ideia de "colapso de tempo". Esses conceitos foram aplicados com a linguagem C++ utilizando a biblioteca OpenCV.
\end{abstract}

\keywords{Hyperlapse, Processamento de Imagem, Vídeo, Estabilização, Shi-Tomasi, Lucas-Kanade, Transformação Afim, OpenCV.}
]

% CONTRIBUIÇÃO

\selectlanguage{brazil}

\section{Introdução}
Um dos campos do Processamento Digital de Imagens é o Fluxo Óptico, o qual estuda o deslocamento dos pixels de uma sequência de imagens.

Inúmeros estudos e técnicas tem surgido nesse ramo, como também as aplicações, podendo ser citadas: navegação de robôs móveis, nesse caso o fluxo óptico atuará no rastreio de objetos fazendo com quê o robô não colida em obstáculos presentes no ambiente em que se encontra, outro exemplo é a estabilização de vídeos, como também a recuperação de formas a partir do movimento e compressão de imagens.

Neste trabalho será citado algumas técnicas de detecção de pontos de borda, além de explicar um pouco mais a fundo o funcionamento de dois métodos em específico, os quais foram utilizados na aplicação desenvolvida: hyperlapse.

Como também será explicado todo o código e a estratégia utilizada. Posteriormente, é exposto os resultados obtidos.

\subsection{Fluxo Óptico}

O Fluxo Óptico proporciona o rastreamento do pixel de uma determinada imagem com relação a outra imagem pré-conhecida, se faz necessário que tenha no mínimo duas imagens para que isso seja possível, em alguns algoritmos, pois há algoritmos que utilizam mais frames no cálculo. Esse movimento poderá surgir a partir da movimentação da câmera ou dos objetos presentes na cena, ademais, supõe-se que o brilho da imagem sofreu uma variância quase imperceptível, ao ponto de não interferir nos algoritmos de rastreamento, observe:\\

$I(x,y,t) = I(x+\Delta x,y+\Delta y,t+\Delta t)$ (1)\\

sendo I a intensidade do pixel, note que, se for pequeno o deslocamento de um frame para outro, $\Delta x$ e $\Delta y$ serão pequenos em um curto espaço de tempo ($\Delta t$), logo o brilho do pixel também não mudará drásticamente \cite{faria}. Outro ponto importante é a vizinha do pixel ter sofrido deslocamento similar.

Muitos métodos já foram desenvolvidos para o cálculo do fluxo óptico, podendo ser citados: os agortimos de Horn e Schunck (1981), Lucas e Kanade (1981), Fleet e Jepson (1990), Harris-Shi-Tomasi(1994), Nesi et al. (1995), Grossmann e Santos-Victor (1997) e Lai e Vemuri (1998).

Foi utilizado os métodos de Shi-Tomasi e Lucas Kanade no presente trabalho com o intuito da obtenção dos deslocamentos em $x$, em $y$ e do ângulo de rotação dos frames de um vídeo e, desse modo, produzir o efeito de hyperlapse no vídeo, através da estabilização dos frames e o aumento de velocidade na exibição de frames por segundo. Esses métodos foram escolhidos pelo fato de poderem ser executados em tempo hábil para uma aplicação de tempo real, diferentemente do algoritmo de Fleet e Jepson, que possuem um custo computacional alto pois é usado muitos quadros simultaneamente \cite{mario}.

Também é importante informar que o problema de abertura é muito comum nesse processo de rastreamento dos pontos, isso ocorre quando o observador não consegue identificar todos os movimentos presentes na imagem, por exemplo, quando um objeto da imagem está se movendo diagonalmente e o observador só consegue identificar o movimento horizontal. Isso é decorrente de uma janela de pequena abertura para a detecção do deslocamento \cite{agostinho}.

Com relação ao hyperlapse, ele é uma técnica da fotografia que mistura o timelapse com a movimentação da câmera, onde o timelapse é o vídeo acelerado dando o efeito de "lapso de tempo" e a movimentação da câmera utiliza a técnica de varredura de imagem dispondo de um foco na imagem \cite{bezerra}.

\subsection{Metodologia}

Resumidamente, a estratégia utilizada foi capturar um frame, obter os pontos de bordas fortes através do método de Shi-Tomasi e, após a obtenção desses dados, o frame seguinte é capturado para o rastreamento dos pontos anteriormente obtidos, nessa fase é utilizado o método de Lucas Kanade. Agora, sabe-se a localização dos pontos em dois frames distintos, logo, é possível saber o deslocamento em $x$, $y$ e o ângulo da rotação do segundo frame tendo como referência o primeiro frame. E então, o deslocamento e rotação inversos são aplicado à imagem com o intuito da estabilização do vídeo.

O trabalho foi desenvolvido utilizando a linguagem C++ e a biblioteca OpenCV. As funções mais importante do algoritmo são: goodFeaturesToTrack(), calcOpticalFlowPyrLK(), estimateRigidTransform() e warpAffine(). Abaixo está descrito o que cada função faz e o método por trás dela.

\begin{itemize}
\item goodFeaturesToTrack()
\end{itemize}

Essa função utiliza o método de Shi-Tomasi, que por sua vez teve como base o método de Harris, o qual busca variação no gradiente da imagem. Primeiro, é preciso calcular a intensidade do pixel, o qual é obtido pela seguinte equação:

$E(u,v) = \sum_{x,y}w(x,y)[I(x+u, y+v)-I(x,y)]^2$

Usando expansão de Taylor,\\

$E(u,v) = \sum{x,y}[I(x,y)+uI_ x+vI_ y-I(x,y)]^2$,\\

expandindo e manipulando se chega a\\

$E(u,v) = \sum_{x,y}u^2I_x^2+2uvI_xI_y+v^2I_y^2$,\\

expressando em matriz temos:

$E(u,v) = \begin{bmatrix} u & v \end{bmatrix} (\sum_{x,y}w(x,y)\begin{bmatrix} I_x^2 & I_xI_y \\ I_xI_y & I_y^2 \end{bmatrix})$.\\

Criando uma variável M:

$M = \sum_{x,y}w(x,y)\begin{bmatrix} I_x^2 & I_xI_y \\ I_xI_y & I_y^2 \end{bmatrix}$,\\

a expressão fica:

$E(u,v) = \begin{bmatrix} u & v \end{bmatrix} M \begin{bmatrix} u \\ v \end{bmatrix}$.\\

A matriz M é usada no cálculo para determinar se uma janela contém possivelmente um canto, esse \textit{score} é calculado através da seguinte equação:
\begin{center}
$R = min(\lambda_1, \lambda_2)$,
\end{center}
onde os $\lambda$ são os autovalores da matriz M. Esse valor precisa ser maior que um limiar, um $\lambda_{min}$ \cite{harris}. Observe a figura abaixo:

\begin{figure}[h]
	\centering
		\graphicspath{ {shitomasi} }		
		\includegraphics[width=7cm]{images/shitomasi_space.png}
		\caption{Método Shi-Tomasi}
		\label{fig:shitomasi}
\end{figure}

A janela só será considerada um canto quando $\lambda_1$ e $\lambda_2 $ estiverem acima do $\lambda_{min}$, ou seja, quando estiver na região verde mostrada na figura \ref{fig:shitomasi}.

\begin{itemize}
\item calcOpticalFlowPyrLK()
\end{itemize}

Calcula o fluxo óptico para um conjunto de características esparsas usando o método não-iterativo Lucas Kanade, o qual assume que o fluxo é constante em pequenas janelas de tamanho $m$ $x$ $m$ e com $m>1$  \cite{martins}. Numerando os pixels de 1 a n chega-se no seguinte conjunto de equações
\begin{center}
$I_{x1}V_x+I_{y1}V_y = -I_{t1}$\\
$I_{x2}V_x+I_{y2}V_y = -I_{t2}$\\
...\\
$I_{xn}V_x+I_{yn}V_y = -I_{tn}$\\
\end{center}

Notação matricial:\\

$\begin{bmatrix} I_{x1} & I_{y1} & I_{z1}\\I_{x2} & I_{y2} & I_{z2}\\ &...& \\ I_{xn} & I_{yn} & I_{zn} \end{bmatrix} \begin{bmatrix} V_x \\ V_y \\ V_z \end{bmatrix} = \begin{bmatrix} -I_{t1}\\-I_{t2}\\...\\-I_{tn} \end{bmatrix}$
\begin{center} 
$\Rightarrow A\vec{v}=-b$
\end{center}

Utilizando o método dos mínimos quadrados para a resolução desse sistema ficamos com\\

$A^T A\vec{v}=A^T(-b)$ ou $\vec{v}=(A^TA)A^T(-b)$\\

E então obtemos\\

$\begin{bmatrix} V_x \\ V_y \end{bmatrix}$ = $\begin{bmatrix} \sum I_{xi}^2 & \sum I_{xi}I_{yi} \\ \sum I_{xi}I_{yi} & \sum I_{yi}^2 \end{bmatrix}^{-1} \begin{bmatrix} -\sum I_{xi}I_{ti} \\ \sum I_{yi}I_{ti} \end{bmatrix}$\\

Um exemplo visual é a figura \ref{fig:image}, é passado como parâmetro a imagem 1, imagem 2 e as bordas da imagem 1, o retorno será as bordas da imagem 2.
\begin{figure}[h]
	\centering
		\graphicspath{ {image} }		
		\includegraphics[width=7cm]{images/Warp_Affine_Tutorial_Theory_0.jpg}
		\caption{Lucas Kanade}
		\label{fig:image}
\end{figure}
\pagebreak
\begin{itemize}
\item estimateRigidTransform()
\end{itemize}

Sendo pré-estabelecido dois vetores de coordenadas de pontos ótimos de borda, essa função retornará uma transformação afim, isto é, retornará o deslocamento em $x$, $y$ e o ângulo $\theta$, como mostrado nas matrizes abaixo \cite{nghiaho1}:\\

R(rotação)= $\begin{bmatrix}
cos(\theta) & -\sin(theta) \\ \sin(\theta) & cos(\theta)
\end{bmatrix}$

S(escalonamento)= $\begin{bmatrix}
s & 0 \\ 0 & s
\end{bmatrix}$

t(translação)= $\begin{bmatrix}
tx \\ ty
\end{bmatrix}$\\

A transformação afim fica
\begin{center}
$T = [RS|t] = \begin{bmatrix}s*cos(\theta) & -s*sin(\theta) & tx \\ s*sin(\theta) & s*cos(\theta) & ty\end{bmatrix}$
\end{center}

\begin{itemize}
\item warpAffine() - \cite{warp}
\end{itemize}

Basicamente, essa função irá aplicar uma matriz de transformação afim a uma imagem, onde essa transformação afim possuirá deslocamento em \textit{x}, em \textit{y}, o escalonamento e a rotação, como mencionado anteriormente. Essa moficação é realizada na imagem através da seguinte equação:\\

$\texttt{dst} (x,y) =  \texttt{src} ( \texttt{M} _{11} x +  \texttt{M} _{12} y +  \texttt{M} _{13}, \texttt{M} _{21} x +  \texttt{M} _{22} y +  \texttt{M} _{23})$\\

Também é de grande relevância citar que a estabilização do vídeo é mostrada em tempo real para o usuário, pois assim que o tratamento é feito no frame, ele é exibido. Diferentemente da aceleração, que é feita apenas no vídeo resultante. Esse funcionamento será explicado na próxima seção.

\subsection{Agoritmo}

Nesta seção será mostrado a estrutura do algoritmo desenvolvido.

Primeiro, há a captura de um frame, chamado de \textit{prev\_image}, e sua conversão para tons de cinza. Para efeito de visibilidade final do usuário, \textit{prev\_image} foi clonado antes da transformação da cor, para que a imagem colorida não seja perdida.

\lstinputlisting[language=cpp,caption={Captura do Primeiro Frame}]{code/01.cpp}

Em seguida, o código entra em um loop para o tratamento dos seguintes frames. Calcula-se os pontos de borda forte de \textit{prev\_image} (\textit{goodFeaturesToTrack}), o próximo frame é capturado e calculado os correspondentes dos pontos encontrados em \textit{prev\_image} (\textit{calcOpticalFlowPyrLK}). Assim como no primeiro frame, o segundo também é clonado criando a nova imagem \textit{next\_color\_image}.

\lstinputlisting[language=cpp,caption={Início do Loop}]{code/02.cpp}

Observe que existe um loop percorrendo \textit{status} (linha 6), isso se dá porque a função \textit{calcOpticalFlowPyrLK} retorna \textit{1} nessa variável caso o ponto de borda tenha sido encontrado em \textit{next\_image}, a função desse for é armazenar apenas os pontos que possuiem correspondentes.

Agora que temos as posições dos pontos de ambos os frames capturados, será usado \textit{estimateRigidTransform} para encontrar a transformação afim. Pode ocorrer dessa matriz não se encontrada, nesse caso ela é substituída por uma matrix identidade. Além disso, a função \textit{estimateRigidTransform} encontra o deslocamento e a rotação que ocorre do primeiro pro segundo argumento passado, então, pensando na transformação inversa, foi passado os pontos do segundo frame como primeiro argumento, e os pontos do primeiro frame como segundo argumento, perceba:

\lstinputlisting[language=cpp,caption={Transformação Afim}]{code/03.cpp}

Caso a matriz de transformação seja encontrada, os valores de deslocamento e rotação estão sendo somados a suas respectivas variáveis que estão acumulando o seu valor ao decorrer dos loops, pois esse deslocamento e rotação que está sendo calculado na matriz \textit{T} tem como referência o frame anterior.

\lstinputlisting[language=cpp,caption={Matriz T e Aplicação}]{code/04.cpp}

O trecho acima mostra o cálculo da matriz de transformação com os novos valores acumulados e o uso da função \textit{warpAffine}, a qual modifica a imagem \textit{next\_color\_image}, onde o resultado será retornado em \textit{new\_image}. Ademais, \textit{new\_image} é recortada com o objetivo de amenizar o efeito que a estabilização causa nas bordas, além de redimensionada com o tamanho inicial do vídeo.

\lstinputlisting[language=cpp,caption={Final}]{code/06.cpp}

Por fim, o frame resultante é mostrado em uma janela e gravado em um vídeo, mais a necessidade de limpar os vetores das posições das bordas. Segue as especificações do vídeo, as quais são colocadas no início do código:

\lstinputlisting[language=cpp,caption={Vídeo Acelerado}]{code/05.cpp}

Sendo esse vídeo exibido com 60 frames por segundo \cite{nghiaho2}.

\subsection{Resultados}

Para exibição dos resultados, foi utilizado o mecanismo de pintar os pontos encontrados em ambos os frames.
\pagebreak

\begin{figure}[H]
	\subfloat[][Sem Estabilização]{\includegraphics[scale=0.28]{images/result_1a}\label{fig:res1a}}\\	
     \subfloat[][Com Estabilização]{\includegraphics[scale=0.28]{images/result_1b}\label{fig:res1b}}
     \caption{Resultado 01}
     \label{fig:resultado1}
\end{figure}
\begin{figure}[H]
	\subfloat[][Sem Estabilização]{\includegraphics[scale=0.28]{images/result_3a}\label{fig:res3a}}\\
	\subfloat[][Com Estabilização]{\includegraphics[scale=0.28]{images/result_3b}\label{fig:res3b}}
	\caption{Resultado 02}
     \label{fig:resultado3}
\end{figure}

As figuras \ref{fig:resultado1} e \ref{fig:resultado3} mostram duas situação em que a aplicação da transformação afim é bem visível, pois é bastante notório a sobra preta na borda das imagem estabilizadas devido ao deslocamento e rotação.

\subsection{Dificuldades}

Pensar em todo os procedimentos e métodos que poderiam ser utilizados nos frames para tratamento da estabilização foi uma das dificuldades, porém, após algumas pesquisas foi possível entrar em um consenso no que poderia ser usado.

Houveram alguns testes, por exemplo, a aplicação de outras funções para se chegar ao valor do deslocamento e rotação da imagem, podendo ser citadas a função \textit{findHomography()} que encontra a transformação de perspectiva entre dois planos, e \textit{warpPerspective()} que aplicaria a transformada encontrada com \textit{findHomography()}. Mas as funções presentes no algoritmo foram as que responderam melhor à intenção do trabalho.

Porém, o probema da movimentação no eixo \textit{z} não foi solucionado, isso ocorre quando a câmera se desloca em direção ao objeto principal da cena ou se distancia. Ao rodar o algoritmo proposto nesse projeto, o resultado do tratamento tem um comportamento inesperado o qual não atende às espectativas.

\subsection{Conclusão}

O algoritmo atendeu bem ao objetivo do trabalho, que no caso é a estabilização e aceleração na visualização dos frames, porém, apenas para um certo tipo de vídeo, o qual a câmera não se movimenta no eixo \textit{z}, ou seja, não se aproxima e não se distancia do foco da imagem. Posteriormente, esse problema pode ser consertado com um estudo mais aprofundado do fluxo óptico.

% BIBLIOGRAFIA
\bibliography{exemplo}
\end{document}
