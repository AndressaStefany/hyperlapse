\documentclass[conference,harvard,brazil,english]{sbatex}
\usepackage{url}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{dred}{rgb}{0.545,0,0}
\definecolor{dblue}{rgb}{0,0,0.545}
\definecolor{lgrey}{rgb}{0.9,0.9,0.9}
\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\lstdefinelanguage{cpp}{
      %backgroundcolor=\color{lgrey},  
      basicstyle=\footnotesize \ttfamily \color{black} \bfseries,   
      breakatwhitespace=false,       
      breaklines=true,               
      captionpos=b,                   
      commentstyle=\color{dkgreen},   
      %deletekeywords={...},          
      escapeinside={\%*}{*)},                  
      %frame=single,                  
      language=C++,                
      keywordstyle=\color{purple},  
      morekeywords={BRIEFDescriptorConfig,string,TiXmlNode,DetectorDescriptorConfigContainer,istringstream,cerr,exit}, 
      identifierstyle=\color{black},
      stringstyle=\color{blue},      
      numbers=left,                 
      numbersep=1pt,                  
      numberstyle=\tiny\color{black}, 
      rulecolor=\color{black},        
      showspaces=false,               
      showstringspaces=false,        
      showtabs=false,                
      stepnumber=1,                   
      tabsize=5,                     
      title=\lstname,                 
    }
\usepackage{ae}
%
% LaTeX2e class SBATeX
%
% Versão 1.0 alpha
%   Walter Fetter Lages
%   w.fetter@ieee.org
%
% Este arquivo cba.tex é uma adaptação do arquivo revista.tex,
% Versão: 1.0 alpha, desenvolvido por Maurício C. de Oliveira,
% mcdeoliveira@ieee.org.
%
% As adaptações fazem com que, por default, sejam utilizadas
% as opções adequadas para o formato do CBA ou SBAI, ao contrário do arquivo
% revista.tex, que, por default, utiliza opções adequadas para o formato
% da Revista da SBA.
%
%
% --------------------------------------------------
%
% Para compilar este exemplo use a seqüência de comandos:
%
%     latex cba
%     bibtex cba
%     latex cba
%     latex cba
%
% Para gerar um arquivo Postscript (.ps):
%
%     dvips -t a4 cba
%
% Para gerar um arquivo Portable Document Format (.pdf):
%
%     dvips -Ppdf -t a4 cba
%     ps2pdf -dMaxSubsetPct=100 -dSubsetFonts=true -dEmbedAllFonts=true -dCompatibilityLevel=1.2 -sPAPERSIZE=a4 cba.ps
%

% --------------------------------------------------
%  Estes comandos são necessários apenas para a
%  a geração deste artigo exemplo. Eles não fazem
%  parte do estilo SBATeX.
% --------------------------------------------------
\makeatletter
\def\verbatim@font{\normalfont\ttfamily\footnotesize}
\makeatother
\usepackage{amsmath}
% --------------------------------------------------


\begin{document}

% CABEÇALHO

\title{Uso do Fluxo Óptico para criação do Hyperlapse}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% O processo de revisao do CBA 2014 sera DOUBLE BLIND, portanto NAO inclua
% autores na versão que será submetida para revisão
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author{Andressa Stéfany Silva de Oliveira}{astefanysoliveira@gmail.com}
\address{Graduanda em Engenharia de Computação\\ Universidade do Rio Grande do Norte\\ Natal, RN, Brasil}

\twocolumn[

\maketitle

\selectlanguage{brazil}
\begin{abstract}
  A partir do estudo de Processamento Digital de Imagens, houve utilização das técnicas de Fluxo Óptico para a estabilização de um vídeo e a aceleração deste, onde o objetivo é a criação do efeito hyperlapse em um vídeo, isto é, a ideia de "colapso de tempo". E esses conceitos foram implementados na linguagem C++ utilizando OpenCV.
\end{abstract}

\keywords{Hyperlapse, Processamento de Imagem, Vídeo, Estabilização, Shi-Tomasi, Lucas-Kanade, Transformação Afim.}
]

% CONTRIBUIÇÃO

\selectlanguage{brazil}

\section{Introdução}
O Fluxo Óptico é o campo de estudo que obtém o deslocamento dos pixels de uma imagem, para isso é necessário possuir no mínimo dois frames, ou seja, uma sequência de frames e assim ser possível fazer o rastreamento do pixel. Há inúmeros aplicações, onde algumas são: navegação de robôs móveis, nesse caso o fluxo óptico atuará no rastreio de objetos fazendo com quê o robô não colida em obstáculos presentes no ambiente em que se encontra, outro exemplo é a estabilização de vídeos, como também a recuperação de formas a partir do movimento e compressão de imagens.

FALTA TERMINAR

\subsection{Fluxo Óptico}

O Fluxo Óptico proporciona o rastreamento de pixel de uma determinada imagem com relação a outra imagem pré-conhecida, se faz necessário que tenha no mínimo duas imagens para que isso seja possível, em alguns algoritmos, pois há algoritmos que utilizam mais frames no cálculo. Esse movimento poderá surgir a partir da movimentação da câmera ou dos objetos presentes na cena, ademais, supõe-se que o brilho da imagem sofreu uma variância quase imperceptível, ao ponto de não interferir nos algoritmos de rastreamento, observe:\\

$I(x,y,t) = I(x+\Delta x,y+\Delta y,t+\Delta t)$ (1)\\

sendo I é a intensidade do pixel, se o deslocamento for pequeno de um frame para outro $\Delta x$ e $\Delta y$ serão pequenos em um curto espaço de tempo ($\Delta t$), logo o brilho do pixel também não mudará drásticamente. Outro ponto importante é a vizinha do pixel ter sofrido deslocamento similar.

Muitos métodos já foram desenvolvidos para o cálculo do fluxo óptico, podendo ser citados: os agortimos de Horn e Schunck (1981), Lucas e Kanade (1981), Fleet e Jepson (1990), Harris-Shi-Tomasi(1994), Nesi et al. (1995), Grossmann e Santos-Victor (1997) e Lai e Vemuri (1998). (MÁRIO SARCINELLI FILHO)

Foi utilizado os métodos de Harris-Shi-Tomasi e Lucas Kanade no presente trabalho com o intuito da obtenção dos deslocamentos em $x$, em $y$ e do ângulo de rotação dos frames de um vídeo e, desse modo, produzir o efeito de hyperlapse no vídeo, através da estabilização dos frames e o aumento de velocidade na exibição de frames por segundo. Esses métodos foram escolhidos pelo fato de poderem serem executados em tempo hábil para uma aplicação de tempo real, diferentemente do Horn e Schunck e do algoritmo de Lai e Vemu-ri, que possuem um custo computacional alto. (pode citar o porquê)

Também é importante informar que o problema de abertura é muito comum nesse processo de rastreamento dos pontos, isso ocorre quando o observador não consegue identificar todos os movimentos presentes na imagem, por exemplo, quando um objeto da imagem está se movendo diagonalmente e o observador só consegue identificar o movimento horizontal. Isso é decorrente de uma janela de pequena abertura para a detecção do deslocamento. (slide agostinho)

Com relação ao hyperlapse, ele é uma técnica da fotografia que mistura o timelapse com a movimentação da câmera, onde o timelapse é o vídeo acelerado dando o efeito de "lapso de tempo" e a movimentação da câmera utiliza a técnica de varredura de imagem dispondo de um foco na imagem. (entrananet)

\subsection{Metodologia}

Resumidamente, a estratégia utilizada foi capturar um frame, obter os pontos de bordas fortes através do método de Shi-Tomasi e, após a obtenção desses dados, o frame seguinte é capturado para o rastreamento dos pontos anteriormente obtidos, nessa fase é utilizado o método de Lucas Kanade. Agora, sabe-se a localização dos pontos em dois frames distintos, logo, é possível saber o deslocamento em $x$, $y$ e o ângulo da rotação do segundo frame tendo como referência o primeiro frame. E então, o deslocamento e rotação inversos são aplicado à imagem com o intuito da estabilização do vídeo.

O trabalho foi desenvolvido utilizando a linguagem C++ e a biblioteca OpenCV. As funções mais importante do algoritmo são: goodFeaturesToTrack(), calcOpticalFlowPyrLK(), estimateRigidTransform() e warpAffine(). Abaixo está descrito o que cada função faz e o método por trás dela.

\begin{itemize}
\item goodFeaturesToTrack()
\end{itemize}

Essa função utiliza o método de Shi-Tomase, que por sua vez teve como base o método de Harris, o qual busca variação no gradiente da imagem. Primeiro, é preciso calcular a intensidade do pixel, o qual é obtido pela seguinte equação:

$E(u,v) = \sum_{x,y}w(x,y)[I(x+u, y+v)-I(x,y)]^2$

Usando expansão de Taylor,

$E(u,v) = \sum{x,y}[I(x,y)+uI_ x+vI_ y-I(x,y)]^2$,

expandindo e manipulando se chega a

$E(u,v) = \sum_{x,y}u^2I_x^2+2uvI_xI_y+v^2I_y^2$,

expressando em matriz temos:

$E(u,v) = \begin{bmatrix} u & v \end{bmatrix} (\sum_{x,y}w(x,y)\begin{bmatrix} I_x^2 & I_xI_y \\ I_xI_y & I_y^2 \end{bmatrix})$.

Criando uma variável M:

$M = \sum_{x,y}w(x,y)\begin{bmatrix} I_x^2 & I_xI_y \\ I_xI_y & I_y^2 \end{bmatrix}$,

a expressão fica:

$E(u,v) = \begin{bmatrix} u & v \end{bmatrix} M \begin{bmatrix} u \\ v \end{bmatrix}$.

A matriz M é usada no cálculo para determinar se uma janela contém possivelmente um canto, esse \textit{score} é calculado através da seguinte equação:\\

$R = min(\lambda_1, \lambda_2)$,

onde os $\lambda$ são os autovalores da matriz M. Esse valor precisa ser maior que um limiar, um $\lambda_{min}$. Observe a figura abaixo: %(harris_detector)

\begin{figure}[h]
	\centering
		\graphicspath{ {shitomasi} }		
		\includegraphics[width=7cm]{images/shitomasi_space.png}
		\caption{Método Shi-Tomasi}
		\label{fig:shitomasi}
		\cite{harvard} %py_shi_tomasi
\end{figure}

A janela só será considerada um canto quando $\lambda_1$ e $\lambda_2 $ estiverem acima do $\lambda_{min}$, ou seja, quando estiver na região verde mostrada na figura \ref{fig:shitomasi}.

\begin{itemize}
\item calcOpticalFlowPyrLK()
\end{itemize}

Calcula o fluxo óptico para um conjunto de características esparsas usando o método não-iterativo Lucas Kanade, o qual assume que o fluxo é constante em pequenas janelas de tamanho $m$ $x$ $m$ e com $m>1$. Numerando os pixels de 1 a n chega-se no seguinte conjunto de equações
\begin{center}
$I_{x1}V_x+I_{y1}V_y = -I_{t1}$\\
$I_{x2}V_x+I_{y2}V_y = -I_{t2}$\\
...\\
$I_{xn}V_x+I_{yn}V_y = -I_{tn}$\\
\end{center}

Notação matricial:\\

$\begin{bmatrix} I_{x1} & I_{y1} & I_{z1}\\I_{x2} & I_{y2} & I_{z2}\\ &...& \\ I_{xn} & I_{yn} & I_{zn} \end{bmatrix} \begin{bmatrix} V_x \\ V_y \\ V_z \end{bmatrix} = \begin{bmatrix} -I_{t1}\\-I_{t2}\\...\\-I_{tn} \end{bmatrix}$
\begin{center} 
$\Rightarrow A\vec{v}=-b$
\end{center}

Utilizando o método dos mínimos quadrados para a resolução desse sistema ficamos com\\

$A^T A\vec{v}=A^T(-b)$ ou $\vec{v}=(A^TA)A^T(-b)$\\

E então obtemos\\

$\begin{bmatrix} V_x \\ V_y \end{bmatrix}$ = $\begin{bmatrix} \sum I_{xi}^2 & \sum I_{xi}I_{yi} \\ \sum I_{xi}I_{yi} & \sum I_{yi}^2 \end{bmatrix}^{-1} \begin{bmatrix} -\sum I_{xi}I_{ti} \\ \sum I_{yi}I_{ti} \end{bmatrix}$ (http://webserver2.tecgraf.puc-rio.br)

Um exemplo visual é a figura \ref{fig:image}, é passado como parâmetro a imagem 1, imagem 2 e as bordas da imagem 1, o retorno será as bordas da imagem 2.

\begin{figure}[h]
	\centering
		\graphicspath{ {image} }		
		\includegraphics[width=7cm]{images/Warp_Affine_Tutorial_Theory_0.jpg}
		\caption{Lucas Kanade}
		\label{fig:image}
		\cite{harvard} %https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.html
\end{figure}

\begin{itemize}
\item estimateRigidTransform()
\end{itemize}

Sendo pré-estabelecido dois vetores de coordenadas de pontos ótimos de borda, essa função retornará um transformação afim, isto é, retornará o deslocamento em $x$, $y$ e o ângulo $\theta$, como mostrado nas matrizes abaixo:

R(rotação)= $\begin{bmatrix}
cos(\theta) & -\sin(theta) \\ \sin(\theta) & cos(\theta)
\end{bmatrix}$

S(escalonamento)= $\begin{bmatrix}
s & 0 \\ 0 & s
\end{bmatrix}$

t(translação)= $\begin{bmatrix}
tx \\ ty
\end{bmatrix}$\\

A transformação afim fica
\begin{center}
$T = [RS|t] = \begin{bmatrix}s*cos(\theta) & -s*sin(\theta) & tx \\ s*sin(\theta) & s*cos(\theta) & ty\end{bmatrix}$
\end{center}
(http://nghiaho.com/?p=2208)
\begin{itemize}
\item warpAffine()
\end{itemize}

Basicamente, essa função irá aplicar uma matriz de transformação afim a uma imagem, onde essa transformação afim possuirá deslocamento em \textit{x}, em \textit{y}, o escalonamento e a rotação, como mencionado anteriormente. Essa moficação é realizada na imagem através da seguinte equação: 

$\texttt{dst} (x,y) =  \texttt{src} ( \texttt{M} _{11} x +  \texttt{M} _{12} y +  \texttt{M} _{13}, \texttt{M} _{21} x +  \texttt{M} _{22} y +  \texttt{M} _{23})$\\

Também é de grande relevância citar que a estabilização do vídeo é mostrada em tempo real para o usuário, pois assim que o tratamento é feito no frame, ele é exibido. Diferentemente da aceleração, que é feita apenas no vídeo resultante. Esse funcionamento será explicado na próxima seção.

\subsection{Agoritmo}

Nesta seção será mostrado a estrutura do algoritmo desenvolvido.

Primeiro, há a captura de um frame, chamado de \textit{prev\_image}, e sua conversão para tons de cinza. Para efeito de visibilidade final do usuário, \textit{prev\_image} foi clonado antes da transformação da cor, para que a imagem colorida não seja perdida.

\lstinputlisting[language=cpp,caption={Captura do Primeiro Frame}]{code/01.cpp}

Em seguida, o código entra em um loop para o tratamento dos seguintes frames. Calcula-se os pontos de borda for de \textit{prev\_image} (\textit{goodFeaturesToTrack}), o próximo frame é capturado e calculado os correspondentes dos pontos encontrados em \textit{prev\_image} (\textit{calcOpticalFlowPyrLK}). Assim como no primeiro frame, o segundo também é clonado criando a nova imagem \textit{next\_color\_image}.

\lstinputlisting[language=cpp,caption={Início do Loop}]{code/02.cpp}

Observe que existe um loop percorrendo \textit{status}, isso se dá porque a função \textit{calcOpticalFlowPyrLK} retorna \textit{1} nessa variável caso o ponto de borda tenha sido encontrado em \textit{next\_image}, a função desse for é armazenar apenas os pontos que possuiem correspondentes.

Agora que temos as posições dos pontos de ambos os frames capturados, será usado \textit{estimateRigidTransform} para encontrar a transformação afim. Pode ocorrer dessa matriz não se encontrada, nesse caso ela é substituída por uma matrix identidade. Além disso, a função \textit{estimateRigidTransform} encontra o deslocamento e a rotação que ocorre do primeiro pro segundo argumento passado, então, pensando na transformação inversa, foi passado os pontos do segundo frame como primeiro argumento, e os pontos do primeiro frame como segundo argumento, perceba:

\lstinputlisting[language=cpp,caption={Transformação Afim}]{code/03.cpp}

Caso a matriz de transformação seja encontrada, os valores de deslocamento e rotação estão sendo somados a suas respectivas variáveis que estão acumulando o seu valor ao decorrer dos loops, pois esse deslocamento e rotação que está sendo calculado na matriz \textit{T} tem como referência o frame anterior.

\lstinputlisting[language=cpp,caption={Matriz T e Aplicação}]{code/04.cpp}

O trecho acima mostra o cálculo da matriz de transformação com os novos valores acumulados e o uso da função \textit{warpAffine}, a qual modifica a imagem \textit{next\_color\_image}, onde o resultado será retornado em \textit{new\_image}. Ademais, \textit{new\_image} é recortada com o objetivo amenizar o efeito que a estabilização causa nas bordas, além de redimensionada com o tamanho inicial do vídeo.

Por fim, o frame resultante é mostrado em uma janela e gravado em um vídeo, segue as especificações do vídeo, as quais são colocadas no início do código:

\lstinputlisting[language=cpp,caption={Vídeo Acelerado}]{code/05.cpp}

Sendo esse vídeo exibido com 60 frames por segundo.

\subsection{Dificuldades}

\subsection{Conclusão}

% BIBLIOGRAFIA
\bibliography{exemplo}
\end{document}
